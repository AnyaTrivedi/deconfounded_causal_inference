{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ppca_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOF96B_8SENw",
        "outputId": "72f987b9-7f86-4f23-ea64-43b052d4a314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_probability in /usr/local/lib/python3.7/dist-packages (0.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (0.5.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (1.21.6)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (0.1.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (1.15.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability) (1.3.0)\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_probability\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import numpy.random as npr\n",
        "from scipy import sparse\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow_probability import edward2 as ed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exposure matrix should be a numpy array or matrix, where each row \n",
        "#represent different user and each column represent different movie/song/book, etc.\n",
        "#It is giving latent factors for each user\n",
        "\n",
        "def GetRowFactors(latent_dim, exposureMatrix):\n",
        "  stddv_datapoints = 0.1\n",
        "  num_datapoints, data_dim = exposureMatrix.shape\n",
        "\n",
        "\n",
        "  # we allow both linear and quadratic model\n",
        "  # for linear model x_n has mean z_n * W\n",
        "  # for quadratic model x_n has mean b + z_n * W + (z_n**2) * W_2\n",
        "  # quadractice model needs to change the checking step accordingly\n",
        "\n",
        "  def ppca_model(data_dim, latent_dim, num_datapoints, stddv_datapoints, form=\"quadratic\"):\n",
        "      w = ed.Normal(loc=tf.zeros([latent_dim, data_dim]),\n",
        "                  scale=tf.ones([latent_dim, data_dim]),\n",
        "                  name=\"w\")  # parameter\n",
        "      z = ed.Normal(loc=tf.zeros([num_datapoints, latent_dim]),\n",
        "                  scale=tf.ones([num_datapoints, latent_dim]), \n",
        "                  name=\"z\")  # local latent variable / substitute confounder\n",
        "      if form == \"linear\":\n",
        "          x = ed.Normal(loc=tf.matmul(z, w),\n",
        "                      scale=stddv_datapoints * tf.ones([num_datapoints, data_dim]),\n",
        "                      name=\"x\")  # (modeled) data\n",
        "      elif form == \"quadratic\":\n",
        "          b = ed.Normal(loc=tf.zeros([1, data_dim]),\n",
        "                  scale=tf.ones([1, data_dim]),\n",
        "                  name=\"b\")  # intercept\n",
        "          w2 = ed.Normal(loc=tf.zeros([latent_dim, data_dim]),\n",
        "                  scale=tf.ones([latent_dim, data_dim]),\n",
        "                  name=\"w2\")  # quadratic parameter\n",
        "          x = ed.Normal(loc=b + tf.matmul(z, w) + tf.matmul(tf.square(z), w2),\n",
        "                      scale=stddv_datapoints * tf.ones([num_datapoints, data_dim]),\n",
        "                      name=\"x\")  # (modeled) data\n",
        "      return x, (w, z)\n",
        "\n",
        "  log_joint = ed.make_log_joint_fn(ppca_model)\n",
        "\n",
        "\n",
        "  def variational_model(qb_mean, qb_stddv, qw_mean, qw_stddv, \n",
        "                      qw2_mean, qw2_stddv, qz_mean, qz_stddv):\n",
        "    qb = ed.Normal(loc=qb_mean, scale=qb_stddv, name=\"qb\")\n",
        "    qw = ed.Normal(loc=qw_mean, scale=qw_stddv, name=\"qw\")\n",
        "    qw2 = ed.Normal(loc=qw2_mean, scale=qw2_stddv, name=\"qw2\")\n",
        "    qz = ed.Normal(loc=qz_mean, scale=qz_stddv, name=\"qz\")\n",
        "    return qb, qw, qw2, qz\n",
        "\n",
        "\n",
        "  log_q = ed.make_log_joint_fn(variational_model)\n",
        "\n",
        "  def target(b, w, w2, z):\n",
        "      \"\"\"Unnormalized target density as a function of the parameters.\"\"\"\n",
        "      return log_joint(data_dim=data_dim,\n",
        "                    latent_dim=latent_dim,\n",
        "                    num_datapoints=num_datapoints,\n",
        "                    stddv_datapoints=stddv_datapoints,\n",
        "                    w=w, z=z, w2=w2, b=b, x=exposureMatrix)\n",
        "\n",
        "  def target_q(qb, qw, qw2, qz):\n",
        "      return log_q(qb_mean=qb_mean, qb_stddv=qb_stddv,\n",
        "                  qw_mean=qw_mean, qw_stddv=qw_stddv,\n",
        "                  qw2_mean=qw2_mean, qw2_stddv=qw2_stddv,\n",
        "                  qz_mean=qz_mean, qz_stddv=qz_stddv,\n",
        "                  qw=qw, qz=qz, qw2=qw2, qb=qb)\n",
        "\n",
        "  qb_mean = tf.Variable(np.ones([1, data_dim]), dtype=tf.float32)\n",
        "  qw_mean = tf.Variable(np.ones([latent_dim, data_dim]), dtype=tf.float32)\n",
        "  qw2_mean = tf.Variable(np.ones([latent_dim, data_dim]), dtype=tf.float32)\n",
        "  qz_mean = tf.Variable(np.ones([num_datapoints, latent_dim]), dtype=tf.float32)\n",
        "  qb_stddv = tf.nn.softplus(tf.Variable(0 * np.ones([1, data_dim]), dtype=tf.float32))\n",
        "  qw_stddv = tf.nn.softplus(tf.Variable(-4 * np.ones([latent_dim, data_dim]), dtype=tf.float32))\n",
        "  qw2_stddv = tf.nn.softplus(tf.Variable(-4 * np.ones([latent_dim, data_dim]), dtype=tf.float32))\n",
        "  qz_stddv = tf.nn.softplus(tf.Variable(-4 * np.ones([num_datapoints, latent_dim]), dtype=tf.float32))\n",
        "\n",
        "  qb, qw, qw2, qz = variational_model(qb_mean=qb_mean, qb_stddv=qb_stddv,\n",
        "                                      qw_mean=qw_mean, qw_stddv=qw_stddv,\n",
        "                                      qw2_mean=qw2_mean, qw2_stddv=qw2_stddv,\n",
        "                                      qz_mean=qz_mean, qz_stddv=qz_stddv)\n",
        "\n",
        "\n",
        "  energy = target(qb, qw, qw2, qz)\n",
        "  entropy = -target_q(qb, qw, qw2, qz)\n",
        "\n",
        "  elbo = energy + entropy\n",
        "\n",
        "\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate = 0.05)\n",
        "  train = optimizer.minimize(-elbo)\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  t = []\n",
        "\n",
        "  num_epochs = 500\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "      sess.run(init)\n",
        "\n",
        "      for i in range(num_epochs):\n",
        "          sess.run(train)\n",
        "          if i % 5 == 0:\n",
        "              t.append(sess.run([elbo]))\n",
        "\n",
        "          b_mean_inferred = sess.run(qb_mean)\n",
        "          b_stddv_inferred = sess.run(qb_stddv)\n",
        "          w_mean_inferred = sess.run(qw_mean)\n",
        "          w_stddv_inferred = sess.run(qw_stddv)\n",
        "          w2_mean_inferred = sess.run(qw2_mean)\n",
        "          w2_stddv_inferred = sess.run(qw2_stddv)\n",
        "          z_mean_inferred = sess.run(qz_mean)\n",
        "          z_stddv_inferred = sess.run(qz_stddv)\n",
        "        \n",
        "  return z_mean_inferred, z_stddv_inferred"
      ],
      "metadata": {
        "id": "4m8w497sSSMP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Ja2SbxRSwF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}